#!/usr/bin/env python3
"""
build_labels_and_download_gsod.py
---------------------------------
1. è®€ labels.csv â†’ ç‚ºæ¯ç­†è§€æ¸¬æ‰¾è·é›¢æœ€è¿‘ä¸”è¦†è“‹ 2015â€“2016 çš„ ISD ç«™
2. æª¢æŸ¥/ä¸‹è¼‰è©²å¹´ GSOD æª” (è‹¥å¤±æ•—è‡ªå‹•æ‰¾ä¸‹ä¸€è¿‘ç«™)
3. å°‡é¸å®šç«™è³‡è¨Šå¯«å› labels_isd.csv
   ä¸‹è¼‰æª”æ”¾ data/raw/gsod/<year>/<station>.csv
"""

from pathlib import Path
import pandas as pd
import numpy as np
import requests
from tqdm import tqdm

# ---------- å¯è‡ªè¡Œä¿®æ”¹ ----------
LABEL_SRC   = Path("data/interim/labels.csv")
ISD_SRC     = Path("data/raw/isd-history.csv")
LABEL_OUT   = Path("data/interim/labels_isd.csv")
GSOD_DIR    = Path("data/raw/gsod")
YEARS_SET   = {2015, 2016}          # åªè™•ç†é€™äº›å¹´ä»½
BASE_URL    = "https://www.ncei.noaa.gov/data/global-summary-of-the-day/access/{year}/{station}.csv"
EARTH_R_KM  = 6371.0
# ---------------------------------

def haversine(lat1, lon1, lat2, lon2):
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2
    return 2 * EARTH_R_KM * np.arcsin(np.sqrt(a))

def load_isd(isd_path: Path) -> pd.DataFrame:
    df = pd.read_csv(isd_path, low_memory=False)
    # åªä¿ç•™è¦†è“‹ 2015â€“2016 çš„ç«™
    df = df[(df["BEGIN"] <= 20150101) & (df["END"] >= 20161231)]
    df = df.dropna(subset=["LAT", "LON"])
    df["USAF_STR"] = df["USAF"].astype(str).str.zfill(6)
    df["WBAN_STR"] = df["WBAN"].astype(str).str.zfill(5)
    df["station_id"] = df["USAF_STR"] + df["WBAN_STR"]
    df["lat_rad"] = np.deg2rad(df["LAT"].astype(float))
    df["lon_rad"] = np.deg2rad(df["LON"].astype(float))
    return df[["station_id","CTRY","LAT","LON","ELEV(M)","BEGIN","END","lat_rad","lon_rad"]]

def download_station_year(station_id: str, year: int) -> bool:
    """ä¸‹è¼‰ GSOD æª”ï¼ŒæˆåŠŸå›å‚³ Trueï¼›404 æˆ–å¤±æ•—å›å‚³ False"""
    dest_dir  = GSOD_DIR / str(year)
    dest_dir.mkdir(parents=True, exist_ok=True)
    dest_file = dest_dir / f"{station_id}.csv"
    if dest_file.exists():                       # å·²ä¸‹è¼‰é
        return True
    url = BASE_URL.format(year=year, station=station_id)
    try:
        r = requests.get(url, timeout=20)
        if r.status_code == 200 and r.content.strip():
            dest_file.write_bytes(r.content)
            return True
    except Exception:
        pass
    return False

def main():
    print("ğŸ“¥ è®€å–è³‡æ–™ â€¦")
    labels = pd.read_csv(LABEL_SRC, low_memory=False)
    isd    = load_isd(ISD_SRC)

    # é å…ˆæº–å‚™ numpy é™£åˆ— (åŠ é€Ÿè·é›¢è¨ˆç®—)
    isd_lat = isd["lat_rad"].to_numpy()
    isd_lon = isd["lon_rad"].to_numpy()

    # for è¿´åœˆæº–å‚™æ¬„ä½å„²å­˜
    out_cols = {k: [] for k in
        ["isd_usaf","isd_wban","isd_ctry","isd_lat","isd_lon","isd_elev","isd_begin","isd_end"]}

    print("ğŸ” ç‚ºæ¯ç­†è§€æ¸¬æŒ‘é¸æœ€è¿‘å¯ç”¨ç«™ä¸¦ä¸‹è¼‰ GSOD â€¦")
    for _, row in tqdm(labels.iterrows(), total=len(labels)):
        lat = np.deg2rad(float(row["st_y"]))
        lon = np.deg2rad(float(row["st_x"]))
        year = pd.to_datetime(row["time"], errors="coerce").year
        if year not in YEARS_SET:
            # ä¸åœ¨é—œæ³¨å¹´ä»½ç¯„åœ â†’ ç›´æ¥å¯«ç©ºæ¬„ä½
            for k in out_cols: out_cols[k].append(np.nan)
            continue

        # ä¾è·é›¢æ’åºç´¢å¼•
        dists = haversine(lat, lon, isd_lat, isd_lon)
        nearest_idx = np.argsort(dists)

        chosen = None
        for idx in nearest_idx:
            station_id = isd.iloc[idx]["station_id"]
            if download_station_year(station_id, year):
                chosen = isd.iloc[idx]
                break      # æ‰¾åˆ°å¯ä¸‹è¼‰çš„ç«™ â†’ çµæŸè¿´åœˆ

        if chosen is not None:
            out_cols["isd_usaf"].append(chosen["station_id"][:6])
            out_cols["isd_wban"].append(chosen["station_id"][6:])
            out_cols["isd_ctry"].append(chosen["CTRY"])
            out_cols["isd_lat"].append(chosen["LAT"])
            out_cols["isd_lon"].append(chosen["LON"])
            out_cols["isd_elev"].append(chosen["ELEV(M)"])
            out_cols["isd_begin"].append(chosen["BEGIN"])
            out_cols["isd_end"].append(chosen["END"])
        else:
            # æ²’æœ‰ä»»ä½•ç«™å¯ä¸‹è¼‰
            for k in out_cols: out_cols[k].append(np.nan)

    # åˆä½µæ¬„ä½ä¸¦è¼¸å‡º
    for col, vals in out_cols.items():
        labels[col] = vals

    LABEL_OUT.parent.mkdir(parents=True, exist_ok=True)
    labels.to_csv(LABEL_OUT, index=False)
    print(f"âœ… å·²è¼¸å‡º {len(labels):,} ç­† â†’ {LABEL_OUT}")

if __name__ == "__main__":
    main()
